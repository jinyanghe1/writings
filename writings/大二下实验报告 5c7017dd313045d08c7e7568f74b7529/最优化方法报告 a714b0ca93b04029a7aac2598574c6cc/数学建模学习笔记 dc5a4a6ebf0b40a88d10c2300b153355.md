# 数学建模学习笔记

# 函数极值与规划模型

本质上是求一个目标函数在线性可行域内的最值问题。目标函数和可行域都可能是高维的。早在高中阶段，我们就知道二维可行域上的线性规划问题。

在此基础上，我们希望讨论更加复杂的规划问题，比如，对于类似目标函数$ax^2+b\log y$，或者对于更加复杂的约束条件，如何保证最优解的存在以及解的最优性就成为了更加有趣的问题。

![非线性规划](%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20dc5a4a6ebf0b40a88d10c2300b153355/Untitled.png)

非线性规划

## 线性规划

对于线性规划，我们可以给出简单的标准形式：

$$
\min_X C^TX \\s.t.\begin{cases}AX\leq b\\ Aeq\cdot X=beq\\ lb\leq X\leq ub \end{cases}
$$

对于不等式约束，我们可以通过一些技巧将其变为等式约束，这样，上面式子可以变成：

$$
\max z = C^TX \\ s.t.\begin{cases}A\tilde X=b \\ \tilde X\geq 0\end{cases}
$$

具体来说，我们通过在不等式约束中引入松弛变量，可以将其变为等式约束。

如：

$$
\max z=x+y \\ s.t.~~~~-3x+2y\leq 3\\ x+y \leq 2 \\ x-y\leq 1\\ x,y\geq 0
$$

可以变换为：

$$
\max z=x+y\\ s.t. z=3+3x-2y\\ u=2-x-y\\ v=1-x+y\\ x,y,z,u,v\geq 0
$$

可以看到这种方法其实将低维问题转换成了高维问题，从而弱化了不等式约束。

线性规划的问题可以形象看作一个求解方程的问题。对线性规划模型来说，有两种简单的解法：单纯形法和蒙特卡洛法。

### 单纯型法

其简单的思想就是固定变量，不断改变基向量，根据输出迭代自己的解。

![Untitled](%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20dc5a4a6ebf0b40a88d10c2300b153355/Untitled%201.png)

可以看到，对于低维问题，单纯型法就是不断迭代，试图找到可行域的“顶点”。

### 蒙特卡洛法

这个方法更为简单，就是在可行域范围内生成大批量的随机数据点，随后在这些数据点中找出最优的。这种方法尤其适用于解的最优性难以证明/确定，或者证明没有最优解的情况。

## 非线性规划

不是所有问题都有很好的线性描述，当等式（不等式）约束是非线性，或者目标函数是非线性的时候，我们就需要解决非线性规划问题。非线性规划问题一般可以写作：

$$
\max f(\mathbf X)\\ s.t. ~~\text{constraint}(\mathbf X)\leq \mathbf C
$$

为了解决这样的多元函数规划问题，一些基本的数学工具是至关重要的。下面列举一些重要的数学概念：

- 多元函数偏微分
- 多元函数的全微分
- 多元函数的极值求解与判定（jacobi矩阵和hessian矩阵）
- 拉格朗日乘子法：这种方法类似线性规划中引入松弛变量，可以通过新变量的引入消去原问题给出的等式约束。如：

$$
\max f(x,y),s.t.~~g(x,y)=0 \\ \iff \max f'(x,y,\lambda)=f(x,y)-\lambda\cdot g(x,y)
$$

- KKT条件：对于不等式约束问题的解决技巧

$$
\min f(x),~~h(x)=0,g(x)\leq 0 \\ \iff \min L(x,\lambda,\mu)=f(x)+\lambda h(x)+\mu g(x)\text{ where} \\ \begin{cases} \frac{\partial L}{\partial X}|_{X=X*}=0\\ \lambda \ne 0 \\ \mu \geq 0 \\ \mu g(X^*)=0\\ h(X^*)=0 \\ g(X^*)\leq 0\end{cases}
$$

## 整数规划

### 0-1规划

表示变量取值只能是0或者1，对应有或者没有的问题。这是离散规划里面最常见的规划问题。

### 指派问题

指派问题的基本模型是$n$个人做$n$项工作，第$i$个人做第$j$项工作的效率为$c_{ij}\geq 0$。应该指派哪个人完成哪项任务，使完成效率最高。

### 分支定界法

解决整数规划的方法有很多种，分支定界法是一个常用的方法。

![Untitled](%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20dc5a4a6ebf0b40a88d10c2300b153355/Untitled%202.png)

### 匈牙利法

![Untitled](%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20dc5a4a6ebf0b40a88d10c2300b153355/Untitled%203.png)

## 动态规划

动态规划其实大多数更加偏向于程序设计问题。此处不赘述。

## 贪心策略

这里也不过多介绍。

# 常用数学工具

## 微分方程

## 差分方程

## 经典的数值计算方法

python中的sympy是一个十分强大的数学计算库，可以用于解决很多数值计算问题。

## 微分方程案例：人口增长的模型

人口问题是微分方程建模的一个典型案例。人口的增长可以用多种模型进行预测。

在模型中我们假设：

1. 不考虑死亡率的影响，只考虑净增长率。
2. 不考虑人口迁移的影响，只考虑自然变化
3. 不考虑重大突发事件的影响

**马尔萨斯模型**：假设增长率永远是常数$r$，则有

$$
x(t+\Delta t)-x(t)=x(t)\cdot r\Delta t \\ x(t)=x_0e^{rt}
$$

这个模型有一些局限性：

1. 种群增长率不一定是一个常数
2. 种群基数越大，增长不一定越快

对上面模型进行一些修正，得到**对数人口增长模型：**

$$
\begin{cases}\frac{dx}{dt}=xr(1-\frac{x}{K})\\ x(0)=x_0\end{cases} \\ x(t)=\frac{K}{1+(\frac{K}{x_0}-1)e^{-rt}}
$$

从求解出的模型可以看出种群的增长有一个上限容量（$K$）。

## 微分方程案例2：放射物的半衰期

放射性物质半衰期的确定和马尔萨斯模型十分类似，因为其浓度的衰减也遵循一个对数模型。

## 数值方法

数值计算方法，是一种研究并且解决数学问题的数值近似解方法，是在计算机上使用的解数学问题的方法，简称计算方法。下面介绍一些常见的数值计算方法。

1. 梯度下降：$f(x+\Delta x)\simeq f(x)+\Delta x\nabla f(x)$。如果规划的目标是使得$f(x+\Delta x)<f(x)$，则需要保证$\Delta x\nabla f(x)<0$。令改变量$\Delta x:=-\alpha \nabla f(x),~~\alpha>0$，就可以不断迭代输入值$x'\leftarrow x-\alpha \nabla f(x)$进行更新。
2. 牛顿法：给定初值$x_0$和精度$\epsilon$，设置$k=0$。计算梯度、海森矩阵$g_k,\mathbf H_k$。如果$||g_k||<\epsilon$，则判定达到了极值点，停止迭代。否则进行如下操作：
    
    $$
    d_k=-\mathbf H_k^{-1}g_k \\ \mathbf X_{k+1}= \mathbf X_k+\gamma d_k
    $$
    
3. 欧拉法：在更新下一个$x$值的时候，对斜率进行改进：
    
    $$
    \mathbf X_k= \mathbf X_{k-1}+ f[(\mathbf X_{k-1}+\mathbf X_k^{(0)})/2]\Delta t
    $$
    
    用于进一步更新的$\mathbf X_k^{(0)}$可以通过简单的梯度下降法或者牛顿法得到。
    
4. 龙格库塔法：这可以看做欧拉法思想的一种推广。其核心思想是欧拉法是将两个点进行平均来预测，而龙格库塔法则是多算几个点，最后一起做平均进行预测。

# 数据处理的基本策略

## 数据的介绍

## 数据预处理

可以考虑对数据进行$min-max$规约：即

$$
\mathbf X \leftarrow \frac{\mathbf X-\min(\mathbf X)}{\max (\mathbf X)-\min(\mathbf X)}
$$

还有Z-score规约：

$$
\mathbf X\leftarrow \frac{\mathbf X-\text{mean}(\mathbf X)}{\text{std}(\mathbf X)}
$$

## 插值和拟合

**线性插值：**根据点斜式方程得到插值函数，补全空缺值。

**拉格朗日插值：**

$$
l_k(x):=\Pi_{i=0,i\ne k}^n \frac{x-x_i}{x_k-x_i}, \\ L_n(x)=\sum_{k=0}^ny_kl_k(x)
$$

**三次样条插值：**在每个小区间内使用三次多项式$I_k$连接，所有三次多项式连接成的分段函数记作$S(x)$，在插值节点上相邻两个三次多项式的一阶导数和二阶导数相等。即：

$$
I_k=a_kx^3+b_kx^2+c_kx+d_k,\ \ k=0,1,\dots,n-1\\ \text{where}\\ S(x_i)=f_i,\ \ i=0,1,\dots,n\\ I_k(x_{k+1})=I_{k+1}(x_{k+1})=f_{k+1}\\ I'_k(x_{k+1})=I'_{k+1}(x_{k+1})\\ I''_k(x_{k+1})=I''_{k+1}(x_{k+1})
$$

# 评价类模型

## 层次分析

成对比较矩阵：对不同分量构建矩阵，不同的值代表“相对重要性”。

一致性检验：

对比较矩阵进行特征值分解，最大的特征值为$\lambda$，定义

$$
CI=\frac{\lambda-n}{n-1}
$$

另外根据随机试验的统计规律有RI表格，通过式子

$$
CR=\frac{CI}{RI}
$$

可以得到一致性检验，当$CR<0.1$时认为有比较满意的一致性。

## 熵权法

熵权法的分析基本遵从这样三步：

1. 数据归一化。
2. 求解信息熵。$E_j=\frac{-\sum_{i=1}^np_{ij}\ln(p_{ij})}{\ln n}$。
3. 得到权值。$\omega_j = \frac{1-E_j}{k-\sum E_j}$。

熵权法的python实现：比较简单。

```python
def entropyWeight(data):
	data = np.array(data)
	p = data / data.sum(axis=0)
	E = np.nansum(-P * np.log(P) / np.log(len(data)), axis=0)
	return (1-E) / (1-E).sum()
```

## TOPSIS分析法

其核心想法就是评估方案系统中任何一个方案距离理想最优解和最劣解的综合距离。理想最优解就是在各个指标上都最优的解。

**数据预处理：**

- 指标正向化：有的指标越大越好，有的越小越好，我们可以对其进行一些预处理，使得这些指标都像考试分数一样越大越好。
- 无量纲化：有的指标数量级区别很大，可以进行一些正则化操作使其落在相同的区间。

**带权距离计算’：**

```python
def topsis(data, weight=None):
	data = data / np.sqrt((data**2).sum())
	
	Z = pd.DataFrame([data.min(),data.max()], index=['负理想解','正理想解'])
	
	weight = entropyWeight(data) if weight is None else np.array(weight)
	Result = data.copy()
	Result['正理想解'] = np.sqrt(((data - Z.loc['正理想解'])**2*weight).sum(axis=1))
	Result['负理想解'] = np.sqrt(((data - Z.loc['负理想解'])**2*weight).sum(axis=1))
	
	Result['综合得分'] = Result['负理想解'] / (Result['负理想解'] + Result['正理想解'])
	
	return Result, Z, weight
```

## 模糊评价法

## CRITIC评价

核心的思想在于数据之间的波动性大小和数据之间的相关性也是重要的信息。

**指标变异性：用第$j$列的标准差来衡量**

$$
S_j=\sigma(X[j])
$$

**用相关系数进行表示指标冲突性：**

$$
R_j=\sum_{i=1}^p (1-r_{ij})\ \ \ r_{ij}\text{是}i,j\text{的相关系数}
$$

**信息量：**

$$
C_j = S_j\times R_j
$$

**客观权重：**

$$
W_j=\frac{C_j}{\sum_{i=1}^pC_j}
$$

## 因子分析

因子分析的基本形式：

$$
X-\mu = AF+\varepsilon
$$

# 进化计算与群体智能

## 遗传算法

遗传算法主要包括下列过程：

1. 编码：把每一个可能解编码为向量，称为染色体或个体，把向量中的每一个元素称为基因。
2. 确定种群：把所有的染色体组成集群，按照预定的目标函数，对每个染色体进行评鉴、计算其适应度的值。
3. 对染色体进行“遗传”操作，同时不断去除适应度值低的染色体。

## 蚁群算法